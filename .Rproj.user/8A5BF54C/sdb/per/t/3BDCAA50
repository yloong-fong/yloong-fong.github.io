{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Data Viz Project - Terrorism\"\nauthor: \"Group 13\"\n---\n\n<style>\nbody {\ntext-align: justify}\n</style>\n\n\n## How, When and Where Do Terrorists Attack?\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(readr)\nterror <- read_csv(\"ussubset.csv\")\n\n# Bar graph for types of attacks \nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(dplyr)\n\nterror$Ideology <- terror$DOM_I\nterror <- terror %>% \n  group_by(attacktype1) %>% \n  mutate(total = n())\n  \nterror1 <- arrange(terror, total)\nterror1$attacktype1 <- factor(terror1$attacktype1, levels = rev(unique(terror1$attacktype1)))\n\n\ngg_type <- ggplot(terror, aes(x = attacktype1_txt, fill = Ideology)) + \n  geom_bar(width = 0.5) + \n  geom_text(aes(x = attacktype1_txt, y = total, label = total), \n            hjust = -0.1, \n            size = 3.5, \n            check_overlap = TRUE) + \n  expand_limits(y = c(0, 120)) +\n  coord_flip() + \n  scale_fill_manual(values = c(\"purple\", \"red\", \"darkgreen\", \"blue\", \"orange\", \"grey\")) +\n  theme_economist_white(base_size = 8) + \n  xlab(\"Type of Attack\") + \n  ylab(\"Number of Attacks\") +\n  labs(title = \"Attack Count for the Different Types of Attacks\")\n\ngg_type\n```\n\nArmed Assualts are the most common form of terrorist attacks, followed by assassination and then bombing. \n\nFor armed assault attacks, a large majority of the terrorism groups adopt the left-wing and right-wing ideologies.\n\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(plotly)\nterror2 <- terror %>% \n  group_by(iyear, Ideology) %>% \n  mutate(total = n(), \n         nkills = sum(nkill))\n\nterror_left <- filter(terror2, Ideology == \"Left-Wing\")\nterror_right <- filter(terror2, Ideology == \"Right-Wing\")\ng <- terror2 %>% group_by(Ideology) %>% \n  plot_ly() %>% layout(title = \"Line graph for Number of Attacks over time\", \n                       xaxis = list(title = \"Year\"), \n                       yaxis = list(title = \"Number of Attacks\")) %>%\n  add_lines(x = terror2$iyear, y = terror2$total, \n            alpha = 0.2, name = \"Other Ideologies\", \n            hoverinfo = 'text', \n           text = ~paste('</br> Year: ', iyear, \n                        '</br> Number of Attacks: ', total, \n                        '</br> Number of Fatalities: ', nkills, \n                        '</br> Ideology: ', Ideology),\n            type = \"scatter\", mode = \"lines\",\n            line = list(color = 'rgba(192,192,192,0.4)')) \n\ng %>%  add_lines(x = terror_left$iyear, y = terror_left$total, \n           name = \"Left-Wing\", \n            hoverinfo = 'text', \n          text = ~paste('</br> Year: ', terror_left$iyear, \n                        '</br> Number of Attacks: ', terror_left$total, \n                        '</br> Number of Fatalities: ', terror_left$nkills, \n                        '</br> Ideology: ', terror_left$Ideology), \n          type = \"scatter\", mode = \"lines\", line = list(color = c('red'))) %>% \n  add_lines(x = terror_right$iyear, y = terror_right$total, \n           name = \"Right-Wing\", \n           hoverinfo = 'text', \n          text = ~paste('</br> Year: ', terror_right$iyear, \n                        '</br> Number of Attacks: ', terror_right$total, \n                        '</br> Number of Fatalities: ', terror_right$nkills, \n                        '</br> Ideology: ', terror_right$Ideology), type = \"scatter\",\n            mode = \"lines\", line = list(color = c('blue'))) \n\n```\n\nThe number of terror attacks fluctuate erratically across the years, though there seem to be a general decrease in number of attacks.\n\nTerrorist groups adopting the left-wing ideologies were the ones who conducted the most number of terrorist attacks from 1970 to 1973. The worst year would be 1970 where the left-wing terrorist groups were involved in 17 attacks which lead to 19 fatalities. However, the number of attacks decreased subsequently and there has not been any attacks organised by left-wing terrorist groups from 1981 onwards.\n\nOn the other hand, the terrorist groups with right-wing ideologies were involved in a moderate number of terror attacks and 7 was the highest number of attacks which they have been involved in the year 1980. But they have still been active in causing terror attacks across the years.\n\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(rgdal)\nlibrary(leaflet)\nlibrary(dplyr)\nlibrary(plyr)\nlibrary(magrittr)\nlibrary(RColorBrewer)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nus_fatal <- read.csv(\"ussubset.csv\")\nusa <- readOGR('cb_2016_us_state_20m.shp', verbose = FALSE)\n\nus_fatal <- us_fatal[us_fatal$latitude >= 24.7433195,]\nus_fatal <- us_fatal[us_fatal$latitude <= 49.3457868,]\nus_fatal <- us_fatal[us_fatal$longitude >= -124.7844079,]\nus_fatal <- us_fatal[us_fatal$longitude <= -66.9513812,]\n\nus_fatal_2010  <- subset(us_fatal, attackdecade==2010)\nus_fatal_2000  <- subset(us_fatal, attackdecade==2000)\nus_fatal_1990  <- subset(us_fatal, attackdecade==1990)\nus_fatal_1980  <- subset(us_fatal, attackdecade==1980)\nus_fatal_1970  <- subset(us_fatal, attackdecade==1970)\n\n\npal = colorFactor(c(\"purple\",\"red\",\"green\",\"blue\",\"orange\",\"black\"), domain = us_fatal$DOM_I) \ncolor_ideology_2010 = pal(us_fatal_2010$DOM_I)\ncolor_ideology_2000 = pal(us_fatal_2000$DOM_I)\ncolor_ideology_1990 = pal(us_fatal_1990$DOM_I)\ncolor_ideology_1980 = pal(us_fatal_1980$DOM_I)\ncolor_ideology_1970 = pal(us_fatal_1970$DOM_I)\n\nleaflet(usa, width =\"100%\", height = \"400px\" ) %>% setView(lat=33, lng=-103 , zoom=3.5) %>% addPolygons(stroke = TRUE, smoothFactor = 0.5, weight=1, color='#333333', opacity=0.5, fillColor = \"white\", label = usa@data$NAME) %>% \n  addCircleMarkers(group=\"2010 attacks\", data=us_fatal_2010, lng = ~longitude, lat = ~latitude, color=color_ideology_2010, fillColor=color_ideology_2010, radius=2*sqrt(us_fatal_2010$nkill), weight=1, opacity = 1,  popup = paste(\"Perpetrator:\",us_fatal_2010$gname,\"<br/>\", \"State:\",us_fatal_2010$provstate,\"<br/>\", \"Date of Attack:\", us_fatal_2010$date,\"<br/>\", \"Ideology:\", us_fatal_2010$DOM_I,\"<br/>\", \"Number of Fatalities:\", us_fatal_2010$nkill, \"<br/>\", \"Attack Type:\",  us_fatal_2010$attacktype1_txt, \"<br/>\")) %>%\n  \n  addCircleMarkers(group=\"2000 attacks\", data=us_fatal_2000, lng = ~longitude, lat = ~latitude, color=color_ideology_2000, fillColor=color_ideology_2000, radius=2*sqrt(us_fatal_2000$nkill), weight=1, opacity = 1,  popup = paste(\"Perpetrator:\",us_fatal_2000$gname,\"<br/>\",\"State:\", us_fatal_2000$provstate,\"<br/>\",\"Date of Attack:\", us_fatal_2000$date,\"<br/>\", \"Ideology:\", us_fatal_2000$DOM_I,\"<br/>\", \"Number of Fatalities:\", us_fatal_2000$nkill, \"<br/>\", \"Attack Type:\",  us_fatal_2000$attacktype1_txt, \"<br/>\")) %>%\n  \n  addCircleMarkers(group=\"1990 attacks\", data=us_fatal_1990, lng = ~longitude, lat = ~latitude, color=color_ideology_1990, fillColor=color_ideology_1990, radius=2*sqrt(us_fatal_1990$nkill), weight=1, opacity = 1,  popup = paste(\"Perpetrator:\",us_fatal_1990$gname,\"<br/>\",\"State:\", us_fatal_1990$provstate,\"<br/>\", \"Date of Attack:\", us_fatal_1990$date,\"<br/>\", \"Ideology:\", us_fatal_1990$DOM_I,\"<br/>\", \"Number of Fatalities:\", us_fatal_1990$nkill, \"<br/>\", \"Attack Type:\",  us_fatal_1990$attacktype1_txt, \"<br/>\")) %>%\n \n   addCircleMarkers(group=\"1980 attacks\", data=us_fatal_1980, lng = ~longitude, lat = ~latitude, color=color_ideology_1980, fillColor=color_ideology_1980, radius=2*sqrt(us_fatal_1980$nkill), weight=1, opacity = 1,  popup = paste(\"Perpetrator:\",us_fatal_1980$gname,\"State:\", us_fatal_1980$provstate,\"<br/>\",\"<br/>\",\"Date of Attack:\", us_fatal_1980$date,\"<br/>\", \"Ideology:\", us_fatal_1980$DOM_I,\"<br/>\", \"Number of Fatalities:\", us_fatal_1980$nkill, \"<br/>\", \"Attack Type:\",  us_fatal_1980$attacktype1_txt, \"<br/>\")) %>%\n  \n  addCircleMarkers(group=\"1970 attacks\", data=us_fatal_1970, lng = ~longitude, lat = ~latitude, color=color_ideology_1970, fillColor=color_ideology_1970, radius=2*sqrt(us_fatal_1970$nkill), weight=1, opacity = 1,  popup = paste(\"Perpetrator:\",us_fatal_1970$gname,\"<br/>\",\"State:\", us_fatal_1970$provstate,\"<br/>\",\"Date of Attack:\", us_fatal_1970$date,\"<br/>\", \"Ideology:\", us_fatal_1970$DOM_I,\"<br/>\", \"Number of Fatalities:\", us_fatal_1970$nkill, \"<br/>\", \"Attack Type:\",  us_fatal_1970$attacktype1_txt, \"<br/>\")) %>%\n  addLegend(pal = pal, values = ~us_fatal$DOM_I, title = \"Ideology of Perpetrator\", position = \"bottomright\") %>%\n    addLayersControl(\noverlayGroups = c(\"2010 attacks\",\"2000 attacks\", \"1990 attacks\", \"1980 attacks\", \"1970 attacks\"),\noptions = layersControlOptions(collapsed = TRUE))  %>% hideGroup(\"2000 attacks\") %>% hideGroup(\"1990 attacks\") %>% hideGroup(\"1980 attacks\") %>% hideGroup(\"1970 attacks\")\n\n```\n\nTo build on the earlier visualizations of summary statistics of the terrorist attacks, the leaflet map above shows the location of the attacks across the years (different layers). The locations are color-coded according to the ideology of the perpetrator as shown in the legend, and sized according to the number of fatilities. Specifics of the attacks including information on the perpetrator, state, date of attack, and type of attack are detailed in pop-ups when the markers are clicked.\n\nThe following are some noteworthy trends from this visualization. Firstly, the number of attacks seem to be decreasing over time as later decades have fewer markers on the map. However, the number of fatilites stemming from each attack tend to be larger for the later attacks as indicated by the larger radius of the markers for the layers corresponding to later decades. Secondly, most of the attacks tend to be driven by religious or right-wing ideologies since most of the markers are either blue or green. Thirdly, attacks occur more frequently in the east coast area around New York and the west coast area around California. The notorious 9/11 attack stands out in this visualization with the large green circle marker in the layer corresponding to 2000-2010 attacks.\n\nFrom the aforementioned takeaways from the visualization, we can infer that security has probably improved in terms of reducing the number of attacks but concurrently, terrorists seem to be going for more major attacks that will result in more fatalities. Moreover, we should be wary of conflicts relating to religious or right-wing ideologies as those seem to be prone to result in a terrorist attack. Finally, the coastal areas should be more wary as they are more likely targets of a terrorist attack.\n\n\n\n\n\n\n## State Level Maps - Are Some States More Vulnerable Than Others\n\n```{r Setup, include=FALSE, results='hide', warning=FALSE, comment = '', echo=FALSE}\ndetach(\"package:rgdal\", unload = TRUE)\ndetach(\"package:leaflet\", unload = TRUE)\ndetach(\"package:dplyr\", unload = TRUE)\ndetach(\"package:plyr\", unload = TRUE)\ndetach(\"package:magrittr\", unload = TRUE)\ndetach(\"package:RColorBrewer\", unload = TRUE)\ndetach(\"package:stringr\", unload = TRUE)\nlibrary(knitr)\nopts_chunk$set(fig.path=\"images/\",\n               cache.path=\"cache/\",\n               cache=FALSE,\n               echo=FALSE,\n               message=FALSE,\n               warning=FALSE)\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(readr)\nussubset <- read_csv(\"ussubset.csv\")\n```\n\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(magrittr)\nlibrary(dplyr)\n# group by decade\nusattacks_decade <- ussubset[c(\"provstate\",\"attacktype1\",\"attackdecade\")]\n# count attacks by state for each decade\nattack_count_decade <- usattacks_decade %>%\n  group_by(provstate, attackdecade) %>%\n  summarise(n = sum(attacktype1)) %>%\n                ungroup() %>%\n                mutate(provstate = reorder(provstate, n))\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(ggplot2)\nattack_decade_heatmap <- ggplot(data = attack_count_decade, aes(x = factor(attackdecade), y = reorder(provstate, n))) +\n  geom_tile(aes(fill = n), colour = \"yellow\") + theme_grey(base_size = 9) + scale_fill_gradient(low = \"light yellow\", high = \"brown\") + labs(x = \"Decade\", y = \"State\", fill = \"Frequency\") + \nscale_x_discrete(expand = c(0, 0)) +\nscale_y_discrete(expand = c(0, 0)) + theme(axis.text.x = element_text(angle = 90, hjust = 0.5)) + ggtitle(\"Number of attacks by state over decades\") + theme(plot.title = element_text(hjust = 0.5))\n\nattack_decade_heatmap\n```\n\nInvestigating potential trends and differences in attacks by state across time, the heatmap above shows the frequency of attacks for each state across the decades. From the heatmap, attacks appear to be most widespread across states in the 1970s and 2010s, with most states having experienced at least one attack in these two decades. On the other hand, a majority of the states did not experience any attack in the 1990s and 2000s, although a higher concentration of attacks in states like New York, District of Columbia and Florida. This may be indicative of a change in trend from having a widespread attack (attacking most states) in earlier years to more focused attacks (on few states), but a reversal to more widespread attacks in the last decade.\n\nAnalysing trends in frequency of attacks for each state, certain states like California, New York and Texas have experienced attacks across all decades, with the highest number of attacks for California and New York especially in the 1970s. This may be indicative of more focused plans in targeting particular states such as these, where these states tend to have the largest population sizes and hence more frequently targeted (potentially to aim for a bigger impact).\n\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(readxl)\nlibrary(maps)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(stringr)\nGDPstate <- read_excel(\"GDPpercap.xls\")\ncolnames(GDPstate)[3] <- \"GDP\"\ncolnames(GDPstate)[2] <- \"state\"\nGDPstate <- GDPstate[,c(2,3)]\nus.states <- map_data(\"state\")\nus.states <- as.data.frame(us.states)\nus.states <- dplyr::rename(us.states, state = region)\nus.states$subregion = NULL\nus.states$state <- str_to_title(us.states$state)\nlibrary(tidyverse)\nstatenames <- as_data_frame(\n  cbind(state=state.name, state.abb = state.abb, \n        state.center.x = state.center$x, \n        state.center.y = state.center$y))\nstatenames <- statenames %>% mutate_each_(funs(as.numeric), \n                 vars=c(\"state.center.x\",\"state.center.y\"))\nus.states <- left_join(us.states, statenames)\nus.states2 <- left_join(us.states, GDPstate)\nggplot(us.states2, \n       aes(x = long, y = lat, group=group, label=state)) + \n  geom_polygon(aes(fill = GDP)) +\n  scale_fill_gradientn(colours=c(\"pink\", \"red\")) +\n  geom_text(data=statenames, inherit.aes = FALSE, \n            aes(label=state.abb, x=state.center.x, \n                y=state.center.y), colour=\"white\") +\n  geom_point(data = us_fatal, aes(x = longitude, y = latitude, size = nkill, group = NULL, label = NULL), colour = \"black\")  +\n  labs(fill = \"GDP per capita (chained 2009 dollars)\", size = \"Number of Fatalities\") +\n  theme_map() + theme(legend.position=\"right\") + coord_map(projection = \"mercator\")\n```\n\nMoving from the broad picture of the details of the terrorist attacks in US as a whole to the specific picture of the relationship between each state and the attacks, we now find a possible reason as to why California and New York are prone to terrorist attacks. Those are two states with very high GDP per capita as portrayed by the Choropleth shading and terrorist groups may think that attacking those states would result in a greater disruption of (economic) activity. As a corollary, it is also worth noting that states with lower GDP per capita (lighter shades) tend to be less affected by terrorist attacks.\n\n\n## Word Cloud - What Drives Terrorist Organizations\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(readxl)\nterror <- read_excel(\"PPT-US_0517dist.xlsx\")\n#View(terror)\nterror <- terror[c(\"DOM_I\",\"PHIL\")]\n\nattach(terror)\nterror$IDEO[DOM_I == 1] <- \"Extreme Right Wing\"\nterror$IDEO[DOM_I == 2] <- \"Extreme Left Wing\"\nterror$IDEO[DOM_I == 3] <- \"Religious\"\nterror$IDEO[DOM_I == 4] <- \"Ethno-nationalist/Separatist\"\nterror$IDEO[DOM_I == 5] <- \"Single Issue\"\nterror$IDEO[DOM_I == -99] <- \"Uncertain\"\ndetach(terror)\n\nterror = terror[!terror$DOM_I == -99,]\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n#subset by ideologies\nright = terror[terror$DOM_I == 1,]\nleft = terror[terror$DOM_I == 2,]\nrelig = terror[terror$DOM_I == 3,]\nethno = terror[terror$DOM_I == 4,]\nsingle = terror[terror$DOM_I == 5,]\n```\n\n\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# using text analysis\nlibrary(tm)\nlibrary(stringr)\nright_text <- data.frame(doc_id=right$DOM_I, text=right$PHIL, stringsAsFactors = FALSE)\ndf_source_right <- DataframeSource(right_text)\ntm_right <- VCorpus(df_source_right)\n\n# our custom vector of stop words\n\nmy_custom_stopwords <- c(\"group\", \"philosophical\", \"movement\", \"ideological\", \"philosophically\", \"philosophy\", \"philosophies\")\ntm2_right <- tm_map(tm_right, content_transformer(tolower))\ntm2_right <- tm_map(tm2_right, removePunctuation)\ntm2_right <- tm_map(tm2_right, removeWords, c(stopwords(\"en\")))\ntm2_right <- tm_map(tm2_right, removeWords, my_custom_stopwords)\ntm2_right <- tm_map(tm2_right, removeNumbers)\nremoveNumPunct <- function(x){gsub(\"[^[:alpha:][:space:]]*\", \"\", x)}\ntm2_right <- tm_map(tm2_right, content_transformer(removeNumPunct))\ntm2_right <- tm_map(tm2_right, stripWhitespace)\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# stemming\nlibrary(SnowballC)\n# Stem all words\ntm_stemmed_right <- tm_map(tm2_right, stemDocument)\n\n# Stem completion\nstemCompletion2 <- function(x, dictionary) {\n   x <- unlist(strsplit(as.character(x), \" \"))\n   x <- x[x != \"\"]\n   x <- stemCompletion(x, dictionary=dictionary)\n   x <- paste(x, sep=\"\", collapse=\" \")\n   PlainTextDocument(stripWhitespace(x))\n}\n\ntm_all_right <- lapply(tm_stemmed_right, stemCompletion2, \n                     dictionary=tm2_right)\n\ntm_right <- VCorpus(VectorSource(tm_all_right))\n\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(tm)\n\ndtm_right<-DocumentTermMatrix(tm_right)\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(tidytext)\nsotu_td_right <- tidy(dtm_right)\n\nsotu_tf_idf_right <-  sotu_td_right %>%\n                bind_tf_idf(term, document, count) %>%  \n                arrange(desc(tf_idf)) \n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# top 300 words using count\ntop_words_right <- sotu_tf_idf_right %>%\n  group_by(term) %>%\n  summarise(n = sum(count)) %>%\n                top_n(n = 300, wt = n)  %>%\n                ungroup() %>%\n                mutate(term = reorder(term, n))\n# Load wordcloud package\nlibrary(wordcloud)\n# Set seed - to make your word cloud reproducible \nset.seed(1)\n# Create purple_gradient\nblue_gradient <- brewer.pal(10, \"Blues\")\n# Drop 2 faintest colors\nblue_gradient <- blue_gradient[-(1:2)]\n\n```\n\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# using text analysis - left wing\nlibrary(tm)\nleft_text <- data.frame(doc_id=left$DOM_I, text=left$PHIL, stringsAsFactors = FALSE)\ndf_source_left <- DataframeSource(left_text)\ntm_left <- VCorpus(df_source_left)\n\n\ntm2_left <- tm_map(tm_left, content_transformer(tolower))\ntm2_left <- tm_map(tm2_left, removePunctuation)\ntm2_left <- tm_map(tm2_left, removeWords, c(stopwords(\"en\")))\ntm2_left <- tm_map(tm2_left, removeWords, my_custom_stopwords)\ntm2_left <- tm_map(tm2_left, removeNumbers)\nremoveNumPunct <- function(x){gsub(\"[^[:alpha:][:space:]]*\", \"\", x)}\ntm2_left <- tm_map(tm2_left, content_transformer(removeNumPunct))\ntm2_left <- tm_map(tm2_left, stripWhitespace)\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# stemming\nlibrary(SnowballC)\n# Stem all words\ntm_stemmed_left <- tm_map(tm2_left, stemDocument)\n\n\n\n# Stem completion\nstemCompletion2 <- function(x, dictionary) {\n   x <- unlist(strsplit(as.character(x), \" \"))\n   x <- x[x != \"\"]\n   x <- stemCompletion(x, dictionary=dictionary)\n   x <- paste(x, sep=\"\", collapse=\" \")\n   PlainTextDocument(stripWhitespace(x))\n}\n\ntm_all_left <- lapply(tm_stemmed_left, stemCompletion2, \n                     dictionary=tm2_left)\n\ntm_left <- VCorpus(VectorSource(tm_all_left))\n\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(tm)\n\ndtm_left<-DocumentTermMatrix(tm_left)\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(tidytext)\nsotu_td_left <- tidy(dtm_left)\n\n\nsotu_tf_idf_left <-  sotu_td_left %>%\n                bind_tf_idf(term, document, count) %>%  \n                arrange(desc(tf_idf)) \n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# top 300 words using count\ntop_words_left <- sotu_tf_idf_left %>%\n  group_by(term) %>%\n  summarise(n = sum(count)) %>%\n                top_n(n = 300, wt = n)  %>%\n                ungroup() %>%\n                mutate(term = reorder(term, n))\n# Load wordcloud package\nlibrary(wordcloud)\n# Set seed - to make your word cloud reproducible \nset.seed(1)\n# Create purple_gradient\nred_gradient <- brewer.pal(10, \"Reds\")\n# Drop 2 faintest colors\nred_gradient <- red_gradient[-(1:2)]\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# using text analysis - religious\nlibrary(tm)\nrelig_text <- data.frame(doc_id=relig$DOM_I, text=relig$PHIL, stringsAsFactors = FALSE)\ndf_source_relig <- DataframeSource(relig_text)\ntm_relig <- VCorpus(df_source_relig)\n\n\ntm2_relig <- tm_map(tm_relig, content_transformer(tolower))\ntm2_relig <- tm_map(tm2_relig, removePunctuation)\ntm2_relig <- tm_map(tm2_relig, removeWords, c(stopwords(\"en\")))\ntm2_relig <- tm_map(tm2_relig, removeWords, my_custom_stopwords)\ntm2_relig <- tm_map(tm2_relig, removeNumbers)\nremoveNumPunct <- function(x){gsub(\"[^[:alpha:][:space:]]*\", \"\", x)}\ntm2_relig <- tm_map(tm2_relig, content_transformer(removeNumPunct))\ntm2_relig <- tm_map(tm2_relig, stripWhitespace)\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE,comment = '', echo=FALSE}\n# stemming\nlibrary(SnowballC)\n# Stem all words\ntm_stemmed_relig <- tm_map(tm2_relig, stemDocument)\n\n# Stem completion\nstemCompletion2 <- function(x, dictionary) {\n   x <- unlist(strsplit(as.character(x), \" \"))\n   x <- x[x != \"\"]\n   x <- stemCompletion(x, dictionary=dictionary)\n   x <- paste(x, sep=\"\", collapse=\" \")\n   PlainTextDocument(stripWhitespace(x))\n}\n\ntm_all_relig <- lapply(tm_stemmed_relig, stemCompletion2, \n                     dictionary=tm2_relig)\n\ntm_relig <- VCorpus(VectorSource(tm_all_relig))\n\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(tm)\n\ndtm_relig<-DocumentTermMatrix(tm_relig)\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(tidytext)\nsotu_td_relig <- tidy(dtm_relig)\n\nsotu_tf_idf_relig <-  sotu_td_relig %>%\n                bind_tf_idf(term, document, count) %>%  \n                arrange(desc(tf_idf)) \n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# top 300 words using count\ntop_words_relig <- sotu_tf_idf_relig %>%\n  group_by(term) %>%\n  summarise(n = sum(count)) %>%\n                top_n(n = 300, wt = n)  %>%\n                ungroup() %>%\n                mutate(term = reorder(term, n))\n# Load wordcloud package\nlibrary(wordcloud)\n# Set seed - to make your word cloud reproducible \nset.seed(1)\n# Create purple_gradient\ngreen_gradient <- brewer.pal(10, \"Greens\")\n# Drop 2 faintest colors\ngreen_gradient <- green_gradient[-(1:2)]\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# using text analysis - ethno\nlibrary(tm)\nethno_text <- data.frame(doc_id=ethno$DOM_I, text=ethno$PHIL, stringsAsFactors = FALSE)\ndf_source_ethno <- DataframeSource(ethno_text)\ntm_ethno <- VCorpus(df_source_ethno)\n\n\ntm2_ethno <- tm_map(tm_ethno, content_transformer(tolower))\ntm2_ethno <- tm_map(tm2_ethno, removePunctuation)\ntm2_ethno <- tm_map(tm2_ethno, removeWords, c(stopwords(\"en\")))\ntm2_ethno <- tm_map(tm2_ethno, removeWords, my_custom_stopwords)\ntm2_ethno <- tm_map(tm2_ethno, removeNumbers)\nremoveNumPunct <- function(x){gsub(\"[^[:alpha:][:space:]]*\", \"\", x)}\ntm2_ethno <- tm_map(tm2_ethno, content_transformer(removeNumPunct))\ntm2_ethno <- tm_map(tm2_ethno, stripWhitespace)\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# stemming\nlibrary(SnowballC)\n# Stem all words\ntm_stemmed_ethno <- tm_map(tm2_ethno, stemDocument)\n\n\n# Stem completion\nstemCompletion2 <- function(x, dictionary) {\n   x <- unlist(strsplit(as.character(x), \" \"))\n   x <- x[x != \"\"]\n   x <- stemCompletion(x, dictionary=dictionary)\n   x <- paste(x, sep=\"\", collapse=\" \")\n   PlainTextDocument(stripWhitespace(x))\n}\n\ntm_all_ethno <- lapply(tm_stemmed_ethno, stemCompletion2, \n                     dictionary=tm2_ethno)\n\ntm_ethno <- VCorpus(VectorSource(tm_all_ethno))\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(tm)\n\ndtm_ethno<-DocumentTermMatrix(tm_ethno)\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(tidytext)\nsotu_td_ethno <- tidy(dtm_ethno)\n\nsotu_tf_idf_ethno <-  sotu_td_ethno %>%\n                bind_tf_idf(term, document, count) %>%  \n                arrange(desc(tf_idf)) \n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# top 300 words using count\ntop_words_ethno <- sotu_tf_idf_ethno %>%\n  group_by(term) %>%\n  summarise(n = sum(count)) %>%\n                top_n(n = 300, wt = n)  %>%\n                ungroup() %>%\n                mutate(term = reorder(term, n))\n# Load wordcloud package\nlibrary(wordcloud)\n# Set seed - to make your word cloud reproducible \nset.seed(1)\n# Create purple_gradient\npurple_gradient <- brewer.pal(10, \"Purples\")\n# Drop 2 faintest colors\npurple_gradient <- purple_gradient[-(1:2)]\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# using text analysis - single\nlibrary(tm)\nsingle_text <- data.frame(doc_id=single$DOM_I, text=single$PHIL, stringsAsFactors = FALSE)\ndf_source_single <- DataframeSource(single_text)\ntm_single <- VCorpus(df_source_single)\n\n\ntm2_single <- tm_map(tm_single, content_transformer(tolower))\ntm2_single <- tm_map(tm2_single, removePunctuation)\ntm2_single <- tm_map(tm2_single, removeWords, c(stopwords(\"en\")))\ntm2_single <- tm_map(tm2_single, removeWords, my_custom_stopwords)\ntm2_single <- tm_map(tm2_single, removeNumbers)\nremoveNumPunct <- function(x){gsub(\"[^[:alpha:][:space:]]*\", \"\", x)}\ntm2_single <- tm_map(tm2_single, content_transformer(removeNumPunct))\ntm2_single <- tm_map(tm2_single, stripWhitespace)\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# stemming\nlibrary(SnowballC)\n# Stem all words\ntm_stemmed_single <- tm_map(tm2_single, stemDocument)\n\n# Stem completion\nstemCompletion2 <- function(x, dictionary) {\n   x <- unlist(strsplit(as.character(x), \" \"))\n   x <- x[x != \"\"]\n   x <- stemCompletion(x, dictionary=dictionary)\n   x <- paste(x, sep=\"\", collapse=\" \")\n   PlainTextDocument(stripWhitespace(x))\n}\n\ntm_all_single <- lapply(tm_stemmed_single, stemCompletion2, \n                     dictionary=tm2_single)\n\ntm_single <- VCorpus(VectorSource(tm_all_single))\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(tm)\n\ndtm_single<-DocumentTermMatrix(tm_single)\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlibrary(tidytext)\nsotu_td_single <- tidy(dtm_single)\n\n\nsotu_tf_idf_single <-  sotu_td_single %>%\n                bind_tf_idf(term, document, count) %>%  \n                arrange(desc(tf_idf)) \n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n# top 300 words using count\ntop_words_single <- sotu_tf_idf_single %>%\n  group_by(term) %>%\n  summarise(n = sum(count)) %>%\n                top_n(n = 300, wt = n)  %>%\n                ungroup() %>%\n                mutate(term = reorder(term, n))\n# Load wordcloud package\nlibrary(wordcloud)\n# Set seed - to make your word cloud reproducible \nset.seed(1)\n# Create purple_gradient\norange_gradient <- brewer.pal(10, \"Oranges\")\n# Drop 2 faintest colors\norange_gradient <- orange_gradient[-(7:10)]\n\n```\n\n```{r, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\nlayout(matrix(c(2, 1), nrow=1), heights=c(1, 4))\npar(mar=rep(0, 4))\nplot.new()\ntext(x=0.5, y=0.5, \"Right-Wing\")\nwordcloud(top_words_right$term, top_words_right$n, \n         max.words = 100, scale=c(2, .2), random.order = FALSE, random.color = FALSE,colors = blue_gradient, main = \"Title\")\nplot.new()\ntext(x=0.5, y=0.5, \"Left-Wing\")\nwordcloud(top_words_left$term, top_words_left$n, \n         max.words = 100, scale=c(2, .2), random.order = FALSE, random.color = FALSE,colors = red_gradient)\nplot.new()\ntext(x=0.5, y=0.5, \"Religious\")\nwordcloud(top_words_relig$term, top_words_relig$n, \n         max.words = 100, scale=c(2, .2), random.order = FALSE, random.color = FALSE,colors = green_gradient)\nplot.new()\ntext(x=0.5, y=0.5, \"Ethno-nationalist\")\nwordcloud(top_words_ethno$term, top_words_ethno$n, \n         max.words = 100,scale=c(2, .2), random.order = FALSE, random.color = FALSE, colors = purple_gradient)\nplot.new()\ntext(x=0.5, y=0.5, \"Single Issue\")\nwordcloud(top_words_single$term, top_words_single$n, \n         max.words = 100,scale=c(2, .2), random.order = FALSE, random.color = FALSE,colors =orange_gradient)\n```\n\nThe founding philosophy describes the group's mission, raison d'etre and epistemological concerns. To investigate the similarities and differences in missions across the ideologies, the word clouds above show the most frequent terms used in describing the founding philosophies of different idologies, colour coded by ideology type.\n\nComparing the terms used in the founding philosophy across the 5 dominant ideologies, there appears to be a common theme of race driving the 5 ideologies, while each taking a different stance, suggestive of groups under these ideologies sparked by racial discontent. Examining the top race-affiliated words for each ideology, there is an apparent difference in racial stance for the first 4 ideologies, with Right-Wing groups focusing on \"white\", Left-Wing groups focusing on \"black\", Religious groups on \"muslim\" and Ethno-nationalist on \"jewish'.\n\nIn addition, there appears to be a common theme of religion with the Right-Wing and Religious groups, with common top words like \"christian\", albeit the latter ideology having missions mostly related to \"islam\".\n\nMoreover, the Left-Wing and Ethno-nationalist appear to have similar philosophies driven by missions for freedom with words like \"struggle\", \"oppressed\" and \"independence\", while the Right-Wing has more \"political\" and \"federal\" concerns. \n\nLastly, the Single Issue groups appear to be driven by a wide spectrum of concerns, with similar concerns with the other ideologies like \"government\" and \"liberation\", but also entirely different issues such as \"animal\", \"cuban\" and \"environment\".\n\n## Network Visualization - How Do They Interact \n\nIn the network visualisation, the colour of the nodes represent the ideology of a terrorist organisation, the size of the node represents the number of years the organisation has been active for, and the line type of each edge represents whether an edge is between nodes who subscribe to the same or different ideologies.\n\nFrom the visualisation, we find terrorist networks are organised into one large interconnected component and five smaller disparate components. The five smaller disparate components are more or less homogenous by ideology and in the large interconnected component, terrorist organisations with the same ideology cluster together,\n\nFrom the names of the terrorist organisations in the five smaller disparate components, we can roughly tell that they comprise a far-right White Nationalist group, a fundamentalist Islamic group, a Cuban ethno-nationalist group, a Zionist group and an anti-communist group. \n\nIn the large inter-connected node, we also see four distinct groups. The first group comprises a Puerto-Rican ethno-nationalist group; the second comprises a far-left group; the third comprises foreign militant organisations, and the fourth comprises environmental groups.\n\nThe visualisation also reveal that the longest-surviving organisations such as Macheteros and the Black Liberation Army are most  central to their groups and the larger network.\n\n\n```{r, dpi=300, fig.align='center', fig.height = 8, fig.width = 8, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n\n#STATIC NETWORK\n\nrequire(rgdal)\nrequire(leaflet)\nrequire(dplyr)\nrequire(plyr)\nrequire(magrittr)\nrequire(RColorBrewer)\nrequire(stringr)\nrequire(igraph)\nrequire(psych)\nrequire(knitr)\nrequire(ggplot2)\nrequire(ggpubr)\nrequire(ggthemes)\nrequire(ggrepel)\nrequire(ggnetwork)\nrequire(igraph)\nrequire(intergraph)\nrequire(extrafont)\nloadfonts()\n\n\ndata <- read.csv(\"Terrorist selected variables.csv\")\ndata <- data[,c(1:41)]\ndata$ORGNAME <- gsub(\"\\\\s*\\\\([^\\\\)]+\\\\)\",\"\",as.character(data$ORGNAME))\ndata$DOM_I<- as.factor(data$DOM_I)\ndata$DOM_I<- revalue(data$DOM_I, c(\"1\"=\"Right-Wing\", \"2\"=\"Left-Wing\", \"3\"=\"Religious\", \"4\"=\"Ethno-nationalist\", \"5\"=\"Single Issue\", \"-99\"=\"Unknown\"))\ndata$DOM_I<- as.character(data$DOM_I)\ndata$ORGNAME<- as.character(data$ORGNAME)\n\nfull_el <- read.csv(\"terroristedgelist.csv\")\nnetwork <- graph.data.frame(full_el)\nmatrix <- get.adjacency(network, sparse=FALSE)\nnetwork <- graph.adjacency(as.matrix(matrix),mode=\"undirected\",weighted=NULL, diag = F) \n\nigraph_el <- as.data.frame(get.edgelist(network, names=TRUE))\ncolnames(igraph_el) <- c(\"Source\", \"Target\")\n\nideology_df <- as.data.frame(cbind(data$ORGNAME,as.character(data$DOM_I)))\ncolnames(ideology_df) <- c(\"ORGNAME\", \"DOM_I\")\nigraph_el <- dplyr::full_join(igraph_el, ideology_df, by = c(\"Source\"=\"ORGNAME\"))\ncolnames(igraph_el)[which(names(igraph_el) == \"DOM_I\")] <- \"Ideology.source\"\nigraph_el <- dplyr::full_join(igraph_el, ideology_df, by = c(\"Target\"=\"ORGNAME\"))\ncolnames(igraph_el)[which(names(igraph_el) == \"DOM_I\")] <- \"Ideology.target\"\n\nigraph_el$Ideology.match <- ifelse(igraph_el$Ideology.source==igraph_el$Ideology.target, 0, 1)\nE(network)$Ideology.match <- igraph_el$Ideology.match\n\ndata$yearsactive <- data$USATK_LAST_YEAR-data$USATK_FIRST_YEAR + 1\ndata$firstdecade <- round_any(data$USATK_FIRST_YEAR, 10, f = floor)\n\nV(network)$Ideology=as.character(data$DOM_I[match(V(network)$name,data$ORGNAME)])\nV(network)$Yearsactive=data$yearsactive[match(V(network)$name,data$ORGNAME)]\nV(network)$Firstdecade=as.character(data$firstdecade[match(V(network)$name,data$ORGNAME)])\n\nset.seed(2104)\nterroristnetwork_df <- ggnetwork(network, layout = \"fruchtermanreingold\", cell.jitter = 0.75)\nterroristnetwork_df$Ideology <- factor(terroristnetwork_df$Ideology, levels = c(\"Right-Wing\", \"Left-Wing\", \"Religious\", \"Ethno-nationalist\", \"Single Issue\"))\nterroristnetwork_df$Yearsactive <- as.numeric(terroristnetwork_df$Yearsactive)\nggplot(terroristnetwork_df, aes(x, y, xend = xend, yend = yend)) + geom_edges(aes(linetype=as.factor(Ideology.match)), alpha = 1, colour=\"gray\") + geom_nodes(aes(color=Ideology, size=Yearsactive), alpha=0.8) + geom_nodelabel_repel(aes(label = vertex.names), label.padding=0.05, size = 2.5, family=\"Garamond\") + ggtitle('Terrorist Networks') + theme_tufte() + theme(legend.position = \"bottom\", legend.box = \"vertical\", plot.title = element_text(hjust = 0.5, face='bold', size=14), text=element_text(family=\"Garamond\"), axis.ticks = element_blank(), axis.text = element_blank(), axis.title = element_blank()) + scale_colour_manual(values = c('blue', 'red', 'green', 'purple', 'orange')) + guides(linetype=FALSE, size=guide_legend(title=\"Years Active\"))\n```\n\n```{r, dpi=300, fig.align='center', fig.height = 10, fig.width = 10, warning=FALSE,message=FALSE,error=FALSE, comment = '', echo=FALSE}\n#INTERACTIVE NETWORK\n\nrequire(visNetwork)\n\nnodes <- as.data.frame(cbind(V(network)$name, V(network)$Ideology, V(network)$Yearsactive))\ncolnames(nodes) <- c(\"id\", \"Ideology\", \"Years Active\")\nnodes$`Years Active` <- as.numeric(as.character(nodes$`Years Active`))\nnodes$Ideology <- factor(nodes$Ideology, levels = c(\"Right-Wing\", \"Left-Wing\", \"Religious\", \"Ethno-nationalist\", \"Single Issue\"))\nlinks <- na.omit(igraph_el)\nlinks <- links [,c(1,2,5)]\ncolnames(links ) <- c(\"from\", \"to\", \"Match\")\nnodes$shape <- \"dot\"  \nnodes$title <- paste(\"Perpetrator:\",nodes$id,\"<br/>\",\"Ideology:\", nodes$Ideology,\"<br/>\", \"Years Active:\", nodes$`Years Active`)\nnodes$label <- nodes$id\nnodes$borderWidth <- 2\nnodes$size <- 8*sqrt(nodes$`Years Active`)\nnodes$group <- nodes$Ideology\nnodes$group <- factor(nodes$group, levels = c(\"Right-Wing\", \"Left-Wing\", \"Religious\", \"Ethno-nationalist\", \"Single Issue\"))\nnodes$color.background <- c('blue', 'red', 'green', 'purple', 'orange')[nodes$Ideology]\nnodes$color.border <- \"gray\"\nnodes$color.highlight.background <- \"black\"\nnodes$color.highlight.border <- \"black\"\nlinks$dashes <- ifelse(links$Match==0, FALSE,TRUE)\nlinks$color <- \"gray\"    \nvisNetwork(nodes, links , width=\"100%\", height=\"500px\", main=\"Terrorist Networks\") %>% visInteraction(navigationButtons = TRUE) %>% visOptions(highlightNearest = TRUE, selectedBy = \"Ideology\") %>% visGroups(groupname = \"Right-Wing\", color = ('lightblue')) %>% visGroups(groupname = \"Left-Wing\", color = ('lightcoral')) %>% visGroups(groupname = \"Religious\", color = ('lightgreen')) %>% visGroups(groupname = \"Ethno-nationalist\", color = ('orchid')) %>% visGroups(groupname = \"Single Issue\", color = ('orange')) %>% visLegend(useGroups = TRUE)\n```",
    "created" : 1525052521681.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "623416442",
    "id" : "3BDCAA50",
    "lastKnownWriteTime" : 1525107220,
    "last_content_update" : 1525107220113,
    "path" : "~/Documents/GitHub/Terrorism-Visualisations/index.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}